#TODO: container based build
#      getting g++-4.9 in container build: http://stackoverflow.com/questions/29312015/building-with-more-than-one-version-of-a-compiler/32127147#32127147

stages:
  - precache
  - test

language: cpp
dist: xenial
sudo: required

os: 
    - linux

compiler:
#    - gcc
    - clang
env:
    - TEST_SUITE=cuda
    - TEST_SUITE=tests
    - TEST_SUITE=parcel
    - TEST_SUITE=icicle
    - TEST_SUITE=KidA
    - TEST_SUITE=UWLCM_MT
    - TEST_SUITE=UWLCM_unit_iles
    - TEST_SUITE=UWLCM_unit_smg
    - TEST_SUITE=MPI_tests
    - TEST_SUITE=MPI_UWLCM_MT MPI=mvapich2
#TODO: MPI icicle test once libmpdata++ has mpi
#TODO: MPI UWLCM test once libmpdata++ and UWLCM have mpi

cache:
  packages: true
  pip: true
  directories:
    - ${TRAVIS_BUILD_DIR}/deps/mvapich2-2.3b
    - ${TRAVIS_BUILD_DIR}/deps/boost
    - ${TRAVIS_BUILD_DIR}/deps/hdf5

# define the precache stage
# empty phases mean that default phases (before_install, install, ...) from the test stage are used (?)
# TODO: precache stage has a lot of unnecessary before_install and install code common to the (default) test stage;
#       add after_success, after_failure to precache, remove building of caches from the test stage, make the build error instead;
aliases:
    # YAML alias for the options common to precache jobs
    - &precache_default
      stage: precache
      install: 
        - . ./.travis_scripts/install_mpi_dependencies.sh
      script: echo "Preparing cache finished"

    - &precache_uwlcm_mpi
      stage: precache
      install: 
        - . ./.travis_scripts/install_mpi_uwlcm_mt_dependencies.sh
      script: echo "Preparing cache finished"

jobs:
    include:
      - <<: *precache_default
        env: TEST_SUITE=MPI_tests
        compiler: gcc
      - <<: *precache_default
        env: TEST_SUITE=MPI_tests
        compiler: clang
      - <<: *precache_uwlcm_mpi
        env: TEST_SUITE=MPI_UWLCM_MT MPI=mvapich2

    exclude:
        - compiler: clang
          env: TEST_SUITE=cuda

        - compiler: clang
          env: TEST_SUITE=MPI_UWLCM_MT MPI=mvapich2

        # UWLCM is not tested on clang yet
        - compiler: clang
          env: TEST_SUITE=UWLCM_MT
        - compiler: clang
          env: TEST_SUITE=UWLCM_unit_iles
        - compiler: clang
          env: TEST_SUITE=UWLCM_unit_smg
addons:
  apt:
    update: true
    packages:
#      - g++-7
#      - gcc-7
#      - clang-4.0
#      - boost1.61
      - python3-dev
      - python3-pip
      - python3-six
      - python3-setuptools
      - python3-numpy
      - python3-scipy
      - libblitz0-dev
      - libthrust-dev
      - libboost # not needed in mpi
      - cmake # installs new cmake from kitware repo, NOTE: the travis cmake (v. 3.12) is still the default, hence we need to call full path to get the new cmake (e.g. /usr/bin/cmake) - a cmake env var added for that
    sources: &sources
#      - sourceline: 'ppa:mhier/libboost-latest'
      - sourceline: 'ppa:rakhimov/boost'
      - sourceline: 'deb http://us.archive.ubuntu.com/ubuntu/ xenial main universe multiverse restricted'
      - sourceline: 'deb https://apt.kitware.com/ubuntu/ xenial main'
        key_url: 'https://apt.kitware.com/keys/kitware-archive-latest.asc'
#      - ubuntu-toolchain-r-test
#      - llvm-toolchain-xenial-4.0


before_install:
# if added in cuda, it upgrades to gcc-5.5, which is not supported by cuda 10-1
#    - if [[ $TEST_SUITE != 'cuda'     ]];  then sudo -E apt-add-repository -y "ppa:ubuntu-toolchain-r/test"; fi

    # define a compiler variable for use in if statements
    - if [[ $CXX == 'clang++' ]]; then export COMPILER=clang++; fi
    - if [[ $CXX == 'g++'     ]]; then export COMPILER=g++; fi

    - export apt_get_install="apt-get install -t xenial --no-install-recommends -y"

    - export cmake="/usr/bin/cmake"

# cuda 10 installation, requires Boost >= 1.65.1
#    - if [[ $TEST_SUITE == 'cuda'     ]];  then wget http://developer.download.nvidia.com/compute/cuda/repos/ubuntu1604/x86_64/cuda-repo-ubuntu1604_10.1.168-1_amd64.deb; fi
#    - if [[ $TEST_SUITE == 'cuda'     ]];  then sudo dpkg -i cuda-repo-ubuntu1604_10.1.168-1_amd64.deb; fi
#    - if [[ $TEST_SUITE == 'cuda'     ]];  then sudo apt-key adv --fetch-keys http://developer.download.nvidia.com/compute/cuda/repos/ubuntu1604/x86_64/7fa2af80.pub; fi
# cuda 8 installation
    - if [[ $TEST_SUITE == 'cuda'     ]];  then wget https://developer.download.nvidia.com/compute/cuda/repos/ubuntu1604/x86_64/cuda-repo-ubuntu1604_8.0.61-1_amd64.deb; fi
    - if [[ $TEST_SUITE == 'cuda'     ]];  then sudo dpkg -i cuda-repo-ubuntu1604_8.0.61-1_amd64.deb; fi

# add runtime path to clang libomp
    - if [[ $CXX == 'clang++' ]]; then export LD_LIBRARY_PATH=/usr/local/clang/lib/:$LD_LIBRARY_PATH; fi

    # locally installed stuff comes first
    - export PATH=/usr/local/bin:$PATH

install:
    - if [[ $TEST_SUITE == 'MPI_tests'     ]]; then . ./.travis_scripts/install_mpi_dependencies.sh; fi
    - if [[ $TEST_SUITE == 'MPI_UWLCM_MT'     ]]; then . ./.travis_scripts/install_mpi_uwlcm_mt_dependencies.sh; fi

    - sudo pip3 install -U pytest --ignore-installed six

    - if [[ $TEST_SUITE == 'cuda'     ]]; then sudo apt-get install -y cuda-toolkit-8-0; fi
    - if [[ $TEST_SUITE == 'cuda'     ]]; then export CUDA_HOME=/usr/local/cuda; fi
    - if [[ $TEST_SUITE == 'cuda'     ]]; then export PATH=${CUDA_HOME}/bin:${PATH}; fi

    - if [[ $TEST_SUITE == 'KidA'     ]]; then sudo $apt_get_install gfortran nco libnetcdf-dev libnetcdff-dev python3-cffi; fi

    # boost
    - if [[ $TEST_SUITE != 'MPI_UWLCM_MT' && $TEST_SUITE != 'MPI_tests'  && $TRAVIS_OS_NAME == 'linux'   ]]; then sudo $apt_get_install boost1.61; fi
    - if [[ $TEST_SUITE != 'MPI_UWLCM_MT' && $TEST_SUITE != 'MPI_tests'  && $TRAVIS_OS_NAME == 'linux'   ]]; then sudo ln -s /usr/lib/x86_64-linux-gnu/libboost_python-py35.so /usr/lib/x86_64-linux-gnu/libboost_python3.so; fi # different naming conventions for boost python with python 3

# thrust
    - git clone --depth=1 git://github.com/thrust/thrust.git;
    - sudo ln -s `pwd`/thrust/thrust /usr/local/include/thrust;
    - if [[ $TEST_SUITE == 'cuda' ]];  then  sudo ln -s `pwd`/thrust/thrust /usr/local/cuda/include/thrust; fi
 
before_script:
    - chmod +x ./.travis_scripts/*

script:
    # compile with nvcc
    - if [[ $TEST_SUITE == 'cuda' ]]; then . ./.travis_scripts/cuda.sh; fi # called like that to pass env vars
    # unit tests and drops.py
    - if [[ $TEST_SUITE == 'tests' ]]; then . ./.travis_scripts/tests.sh; fi
    # parcel
    - if [[ $TEST_SUITE == 'parcel' ]]; then . ./.travis_scripts/parcel.sh; fi
    # icicle
    - if [[ $TEST_SUITE == 'icicle' ]]; then . ./.travis_scripts/icicle.sh; fi
    # UWLCM
    - if [[ $TEST_SUITE == 'UWLCM_MT' ]]; then . ./.travis_scripts/UWLCM.sh moist_thermal; fi
    - if [[ $TEST_SUITE == 'UWLCM_unit_iles' ]]; then . ./.travis_scripts/UWLCM.sh unit_iles; fi
    - if [[ $TEST_SUITE == 'UWLCM_unit_smg' ]]; then . ./.travis_scripts/UWLCM.sh unit_smg; fi
    # KiD-A 1D
    - if [[ $TEST_SUITE == 'KidA' ]]; then . ./.travis_scripts/KidA.sh; fi
    # unit tests and drops.py with MPI (drop drops here?)
    - if [[ $TEST_SUITE == 'MPI_tests' ]]; then . ./.travis_scripts/tests.sh; fi

